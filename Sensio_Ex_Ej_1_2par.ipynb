{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otrilas/IA/blob/main/Sensio_Ex_Ej_1_2par.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo21-Wz9Oy5s"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/024_mlp_clasificacion/mlp_clasificacion.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIcwrLI1Oy5v"
      },
      "source": [
        "# El Perceptrón Multicapa - Clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7_A_QZNOy5v"
      },
      "source": [
        "## El Perceptrón Multicapa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMEAf6NeOy5w"
      },
      "source": [
        "En el [post](https://sensioai.com/blog/023_mlp_backprop) anterior hemos introducido el modelo de `Perceptrón Multicapa`, o MLP, la arquitectura de red neuronal más básica basada en el [Perceptrón](https://sensioai.com/blog/012_perceptron1). Hemos visto cómo calcular la salida de un MLP de dos capas a partir de unas entradas y cómo encontrar los pesos óptimos para una tarea de regresión. En este post vamos a mejorar la implementación de nuestro MLP de dos capas para que sea capaz también de llevar a cabo tareas de clasificación.\n",
        "\n",
        "![](https://www.researchgate.net/profile/Mohamed_Zahran6/publication/303875065/figure/fig4/AS:371118507610123@1465492955561/A-hypothetical-example-of-Multilayer-Perceptron-Network.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8zMhEphOy5w"
      },
      "source": [
        "## Implementación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMGNyHYNOy5x"
      },
      "source": [
        "La mayoría del código que utilizaremos fue desarrollado para el `Perceptrón` y lo puedes encontrar en este [post](https://sensioai.com/blog/018_perceptron_final). Lo único que cambiaremos es la lógica del modelo, el resto de funcionalidad (funciones de pérdida, funciones de activación, etc, siguen siendo exactamente igual)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ7S9iaBOy5x"
      },
      "source": [
        "### Funciones de activación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E1Q87fgOy5y"
      },
      "source": [
        "Para la capa oculta de nuestro MLP utilizaremos una función de activación de tipo `relu`, de la cual necesitaremos su derivada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:53.041393Z",
          "start_time": "2020-08-05T16:49:53.024396Z"
        },
        "id": "SuCOLV2gOy5y"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def reluPrime(x):\n",
        "  return x > 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PkA57JgOy50"
      },
      "source": [
        "En cuanto a las funciones de activación que utilizaremos a la salida del MLP, éstas son las que hemos introducido en posts anteriores:\n",
        "\n",
        "- Lineal: usada para regresión (junto a la función de pérdida MSE).\n",
        "- Sigmoid: usada para clasificación binaria (junto a la función de pérdida BCE).\n",
        "- Softmax: usada para clasificación multiclase (junto a la función de pérdida crossentropy, CE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:53.311543Z",
          "start_time": "2020-08-05T16:49:53.298548Z"
        },
        "id": "ERFwbCS0Oy50"
      },
      "outputs": [],
      "source": [
        "def linear(x):\n",
        "    return x\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.exp(x).sum(axis=-1,keepdims=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AdN0xUlOy50"
      },
      "source": [
        "### Funciones de pérdida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtUZnYlgOy51"
      },
      "source": [
        "Como acabamos de comentar en la sección anterior, estas son las funciones de pérdida que hemos visto hasta ahora para las diferentes tareas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:53.677416Z",
          "start_time": "2020-08-05T16:49:53.673343Z"
        },
        "id": "AUd7yQjBOy51"
      },
      "outputs": [],
      "source": [
        "# Mean Square Error -> usada para regresión (con activación lineal)\n",
        "def mse(y, y_hat):\n",
        "    return np.mean((y_hat - y.reshape(y_hat.shape))**2)\n",
        "\n",
        "# Binary Cross Entropy -> usada para clasificación binaria (con sigmoid)\n",
        "def bce(y, y_hat):\n",
        "    return - np.mean(y.reshape(y_hat.shape)*np.log(y_hat) - (1 - y.reshape(y_hat.shape))*np.log(1 - y_hat))\n",
        "\n",
        "# Cross Entropy (aplica softmax + cross entropy de manera estable) -> usada para clasificación multiclase\n",
        "def crossentropy(y, y_hat):\n",
        "    logits = y_hat[np.arange(len(y_hat)),y]\n",
        "    entropy = - logits + np.log(np.sum(np.exp(y_hat),axis=-1))\n",
        "    return entropy.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FP6715ROy52"
      },
      "source": [
        "Y sus derivadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:53.945375Z",
          "start_time": "2020-08-05T16:49:53.925371Z"
        },
        "id": "flDd4XbBOy52"
      },
      "outputs": [],
      "source": [
        "def grad_mse(y, y_hat):\n",
        "    return y_hat - y.reshape(y_hat.shape)\n",
        "\n",
        "def grad_bce(y, y_hat):\n",
        "    return y_hat - y.reshape(y_hat.shape)\n",
        "\n",
        "def grad_crossentropy(y, y_hat):\n",
        "    answers = np.zeros_like(y_hat)\n",
        "    answers[np.arange(len(y_hat)),y] = 1    \n",
        "    return (- answers + softmax(y_hat)) / y_hat.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeUNcjs4Oy52"
      },
      "source": [
        "### Implementación MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6QtEkMaOy53"
      },
      "source": [
        "Ahora que ya tenemos definidas las diferentes funciones de activación y de pérdida que necesitamos, vamos a implementar nuestro MLP de dos capas capaz de llevar a cabo tanto tareas de regresión como de clasificación. Del mismo modo que ya hicimos con el `Perceptrón`, definiremos una clase base que servirá para la implementación de las clases particulares para cada caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:54.342062Z",
          "start_time": "2020-08-05T16:49:54.325063Z"
        },
        "code_folding": [
          3,
          14,
          20,
          55
        ],
        "id": "rMzDvROYOy53"
      },
      "outputs": [],
      "source": [
        "# clase base MLP \n",
        "\n",
        "class MLP():\n",
        "  def __init__(self, D_in, H, D_out, loss, grad_loss, activation):\n",
        "    # pesos de la capa 1\n",
        "    self.w1, self.b1 = np.random.normal(loc=0.0,\n",
        "                                  scale=np.sqrt(2/(D_in+H)),\n",
        "                                  size=(D_in, H)), np.zeros(H)\n",
        "    # pesos de la capa 2\n",
        "    self.w2, self.b2 = np.random.normal(loc=0.0,\n",
        "                                  scale=np.sqrt(2/(H+D_out)),\n",
        "                                  size=(H, D_out)), np.zeros(D_out)\n",
        "    self.ws = []\n",
        "    # función de pérdida y derivada\n",
        "    self.loss = loss\n",
        "    self.grad_loss = grad_loss\n",
        "    # función de activación\n",
        "    self.activation = activation\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # salida de la capa 1\n",
        "    self.h_pre = np.dot(x, self.w1) + self.b1\n",
        "    self.h = relu(self.h_pre)\n",
        "    # salida del MLP\n",
        "    y_hat = np.dot(self.h, self.w2) + self.b2 \n",
        "    return self.activation(y_hat)\n",
        "    \n",
        "  def fit(self, X, Y, epochs = 10000000, lr = 0.00001, batch_size=None, verbose=True, log_each=1):\n",
        "    batch_size = len(X) if batch_size == None else batch_size\n",
        "    batches = len(X) // batch_size\n",
        "    l = []\n",
        "    for e in range(1,epochs+1):     \n",
        "        # Mini-Batch Gradient Descent\n",
        "        _l = []\n",
        "        for b in range(batches):\n",
        "            # batch de datos\n",
        "            x = X[b*batch_size:(b+1)*batch_size]\n",
        "            y = Y[b*batch_size:(b+1)*batch_size] \n",
        "            # salida del perceptrón\n",
        "            y_pred = self(x) \n",
        "            # función de pérdida\n",
        "            loss = self.loss(y, y_pred)\n",
        "            _l.append(loss)        \n",
        "            # Backprop \n",
        "            dldy = self.grad_loss(y, y_pred) \n",
        "            grad_w2 = np.dot(self.h.T, dldy)\n",
        "            grad_b2 = dldy.mean(axis=0)\n",
        "            dldh = np.dot(dldy, self.w2.T)*reluPrime(self.h_pre)      \n",
        "            grad_w1 = np.dot(x.T, dldh)\n",
        "            grad_b1 = dldh.mean(axis=0)\n",
        "            # Update (GD)\n",
        "            self.w1 = self.w1 - lr * grad_w1\n",
        "            self.b1 = self.b1 - lr * grad_b1\n",
        "            self.w2 = self.w2 - lr * grad_w2\n",
        "            self.b2 = self.b2 - lr * grad_b2\n",
        "        l.append(np.mean(_l))\n",
        "        # guardamos pesos intermedios para visualización\n",
        "        self.ws.append((\n",
        "            self.w1.copy(),\n",
        "            self.b1.copy(),\n",
        "            self.w2.copy(),\n",
        "            self.b2.copy()\n",
        "        ))\n",
        "        if verbose and not e % log_each:\n",
        "            print(f'Epoch: {e}/{epochs}, Loss: {np.mean(l):.5f}')\n",
        "\n",
        "  def predict(self, ws, x):\n",
        "    w1, b1, w2, b2 = ws\n",
        "    h = relu(np.dot(x, w1) + b1)\n",
        "    y_hat = np.dot(h, w2) + b2\n",
        "    return self.activation(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:57:40.536617Z",
          "start_time": "2020-08-05T16:57:40.515590Z"
        },
        "id": "3ojxrrAVOy53"
      },
      "outputs": [],
      "source": [
        "# MLP para regresión\n",
        "class MLPRegression(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, mse, grad_mse, linear)\n",
        "\n",
        "# MLP para clasificación binaria\n",
        "class MLPBinaryClassification(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, bce, grad_bce, sigmoid)\n",
        "\n",
        "# MLP para clasificación multiclase\n",
        "class MLPClassification(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, crossentropy, grad_crossentropy, linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRF4VvHsOy54"
      },
      "source": [
        "Vamos a probar ahora nuestra implementación para diferentes ejemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8BQs7pJOy54"
      },
      "source": [
        "## Regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKkRi3W3Oy54"
      },
      "source": [
        "En primer lugar, vamos a replicar los resultados obtenidos en el post anterior para verificar que nuestro modelo de MLP sigue funcionando bien."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utilizado para manejos de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Computacion vectorial y cientifica para python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Librerias para graficación (trazado de gráficos)\n",
        "from matplotlib import pyplot\n",
        "from mpl_toolkits.mplot3d import Axes3D  # Necesario para graficar superficies 3D\n",
        "import matplotlib.pyplot as plt\n",
        "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "2VOGUYMKWJU0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer datos separados por una coma\n",
        "data = np.loadtxt(os.path.join('DATASET.csv'), delimiter=',')\n",
        "X, y = data[:,: 7], data[:,7]\n",
        "m = y.size\n",
        "print(f'datos x: {X}')\n",
        "print(f'datos y: {y}')\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZyWQLP99vMZ",
        "outputId": "5cd0b492-f649-4463-dcad-cb2344cc57cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datos x: [[2.000e+00 2.011e+03 2.000e+00 ... 2.000e+00 1.000e+00 2.000e+00]\n",
            " [2.000e+00 2.016e+03 3.000e+00 ... 1.000e+00 1.000e+00 2.000e+00]\n",
            " [2.000e+00 2.016e+03 2.000e+00 ... 1.000e+00 1.000e+00 2.000e+00]\n",
            " ...\n",
            " [1.700e+01 2.001e+03 2.000e+00 ... 2.000e+00 1.000e+00 2.000e+00]\n",
            " [1.200e+01 1.985e+03 1.000e+00 ... 1.000e+00 1.000e+00 2.000e+00]\n",
            " [1.200e+01 1.985e+03 1.000e+00 ... 2.000e+00 1.000e+00 2.000e+00]]\n",
            "datos y: [ 99856. 977011. 977011. ...   2001.   2000.   2000.]\n",
            "(1161, 7)\n",
            "(1161,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def  normalizacion(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "    \n",
        "    return X_norm, mu, sigma"
      ],
      "metadata": {
        "id": "38Nl6sDF92d5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_norm, mu, sigma = normalizacion(X)\n",
        "X_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgH3f8oR95e5",
        "outputId": "b9a15222-b954-48a0-9c7d-31982dd0dbe3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.27462736, -0.08822311,  0.09637895, ...,  1.14575259,\n",
              "        -0.25994598,  0.40845339],\n",
              "       [-1.27462736,  0.58830943,  1.32600486, ..., -0.87278877,\n",
              "        -0.25994598,  0.40845339],\n",
              "       [-1.27462736,  0.58830943,  0.09637895, ..., -0.87278877,\n",
              "        -0.25994598,  0.40845339],\n",
              "       ...,\n",
              "       [ 0.6268319 , -1.44128817,  0.09637895, ...,  1.14575259,\n",
              "        -0.25994598,  0.40845339],\n",
              "       [-0.00698785, -3.60619227, -1.13324697, ..., -0.87278877,\n",
              "        -0.25994598,  0.40845339],\n",
              "       [-0.00698785, -3.60619227, -1.13324697, ...,  1.14575259,\n",
              "        -0.25994598,  0.40845339]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X_norm)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "m78N_pAXXtWL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:50:02.227502Z",
          "start_time": "2020-08-05T16:50:02.114509Z"
        },
        "id": "OcVl5pixOy54",
        "outputId": "e7a41226-052a-4e20-cbb0-542b0d5ffef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=14)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC2v1zlqEMjc",
        "outputId": "0352942a-da2d-4a4b-ccc9-2a1048f59fb8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1161, 7)\n",
            "(1161,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Regrecion lineal Ajustando a una linea\n",
        "model = MLPRegression(D_in=1, H=3, D_out=1)\n",
        "epochs, lr = 50000, 0.001\n",
        "model.fit(X.reshape(len(X),7), y, epochs, lr, log_each=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "2hbrKhXLYt5b",
        "outputId": "0014c97c-9dbb-429a-b11e-c62c0ccc7245"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-fc95c0f477b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_each\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-e840e114bf06>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, epochs, lr, batch_size, verbose, log_each)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# salida del perceptrón\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m# función de pérdida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e840e114bf06>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# salida de la capa 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# salida del MLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (1161,7) and (1,3) not aligned: 7 (dim 1) != 1 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_new = np.linspace(0, 12, 100)\n",
        "x_new = x_new.reshape(len(x_new),1)\n",
        "y_pred = model(x_new)\n",
        "    \n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.plot(x_new, y_pred, \"-k\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=14)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fnOlCPa4qMd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_ = np.array(X_norm)\n",
        "y_ = np.array(y)\n",
        "print(X_.shape)\n",
        "print(y_.shape)"
      ],
      "metadata": {
        "id": "qxEBtfp6rXqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4a3b24-2e79-42f0-9707-d6ab5a94791f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1161, 7)\n",
            "(1161,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:58.833975Z",
          "start_time": "2020-08-05T16:49:58.619932Z"
        },
        "id": "8VnunkQ7Oy56",
        "outputId": "cb607256-b190-4d45-e527-8128953021f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1cd05548da49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_each\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-e840e114bf06>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, epochs, lr, batch_size, verbose, log_each)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# salida del perceptrón\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m# función de pérdida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e840e114bf06>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# salida de la capa 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# salida del MLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (3,7) and (1,3) not aligned: 7 (dim 1) != 1 (dim 0)"
          ]
        }
      ],
      "source": [
        "#Redes neuronales con multiples neuronas\n",
        "model1 = MLPRegression(D_in=1, H=3, D_out=1)\n",
        "epochs1, lr1 = 50000, 0.001\n",
        "model1.fit(X_.reshape(len(X_),7), y, epochs1, lr1, batch_size=3, log_each=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:58.945929Z",
          "start_time": "2020-08-05T16:49:58.835932Z"
        },
        "id": "DNLbLqMzOy56"
      },
      "outputs": [],
      "source": [
        "x_new = np.linspace(0, 12, 100)\n",
        "x_new = x_new.reshape(len(x_new),1)\n",
        "y_pred = model(x_new)\n",
        "    \n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.plot(x_new, y_pred, \"-k\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=14)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9y_KJ1MOy56"
      },
      "source": [
        "Como puedes observar nuestro MLP es capaz de ajustarse a datos que no sigan una distribución lineal. Ésta es la principal limitación del `Perceptrón`, es un modelo muy simple, y el MLP es capaz de solventar este problema (siempre y cuando usemos funciones de activación no lineales en la capa oculta. ¿Sabes por qué? Puedes encontrar la respuesta en el [post](https://sensioai.com/blog/023_mlp_backprop) anterior)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnWdxRwGOy5-"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjshHF0_Oy5-"
      },
      "source": [
        "En este post hemos visto como implementar un `Perceptrón Multicapa` en `Python` para tareas de regresión y clasificación. Como ya hicimos anteriormente para el caso del `Perceptrón` hemos validado nuestra implementación con el dataset de clasificación de flores *Iris*, tanto para clasificación binaria como multiclase. Sin embargo, nuestra implementación está muy limitada. ¿Qué pasa si queremos usar un MLP de más de dos capas?, ¿y si queremos usar una función de activación diferente a la `relu` en la capa oculta?, ¿podríamos utilizar un algoritmo de optimizaciñon diferente al `descenso por gradiente`? Para poder hacer todo esto necesitamos un `framework` más flexible, similar a lo que nos ofrecen `Pytorch` y `Tensorflow`. En el siguiente post desarrollaremos nuestro propio framework de MLP para que sea más flexible y que también nos servirá para entender cómo funcionan el resto de frameworks de `redes neuronales` por dentro."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Sensio_Ex_Ej_1_2par.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}